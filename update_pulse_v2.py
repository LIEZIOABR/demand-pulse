import pandas as pd
from pytrends.request import TrendReq
import json
import time
import random
import requests
import os
from datetime import datetime

os.environ['USER_AGENT'] = 'Mozilla/5.0 (DemandPulseBot/2.0)'

# =================================================================
# ABR ALL-IN-ONE - MOTOR DE INTELIG√äNCIA V3.0 (CORRIGIDO)
# TOP 3 ORIGENS: Agora busca CIDADES REAIS via Google Trends
# =================================================================

print("üöÄ INICIANDO DEMAND PULSE V3.0 - VERS√ÉO CORRIGIDA")
print("=" * 60)

def get_weather(lat, lon):
    """Coleta previs√£o de 7 dias usando Open-Meteo."""
    try:
        url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&daily=temperature_2m_max,weathercode&timezone=America%2FSao_Paulo"
        response = requests.get(url, timeout=10)
        data = response.json()
        weather_map = {
            0: "Ensolarado", 1: "Limpo", 2: "Parc. Nublado", 3: "Nublado",
            45: "Nevoeiro", 48: "Nevoeiro", 51: "Garoa", 61: "Chuva Leve",
            63: "Chuva", 71: "Neve", 80: "Pancadas Chuva", 95: "Trovoada"
        }
        forecast = []
        if 'daily' in data:
            for i in range(min(7, len(data['daily']['temperature_2m_max']))):
                code = data['daily']['weathercode'][i]
                forecast.append({
                    "max": data['daily']['temperature_2m_max'][i],
                    "cond": weather_map.get(code, "Est√°vel")
                })
        return {"daily": forecast if forecast else [{"max": 20, "cond": "Est√°vel"}] * 7}
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erro clima: {e}")
        return {"daily": [{"max": 20, "cond": "Est√°vel"}] * 7}


def get_geographic_origins(pytrends, keyword, retries=3):
    """
    Busca as TOP 3 CIDADES/REGI√ïES de origem da demanda via Google Trends.
    CORRE√á√ÉO CR√çTICA: Agora retorna CIDADES reais, n√£o destinos!
    """
    for attempt in range(retries):
        try:
            print(f"      üîç Buscando origens geogr√°ficas (tentativa {attempt + 1}/{retries})...")
            
            # Busca interesse por regi√£o (cidades)
            pytrends.build_payload([keyword], geo='BR', timeframe='today 3-m')
            interest_by_region = pytrends.interest_by_region(
                resolution='CITY',
                inc_low_vol=False,
                inc_geo_code=False
            )
            
            if interest_by_region.empty or keyword not in interest_by_region.columns:
                print(f"      ‚ö†Ô∏è  Sem dados de regi√£o para {keyword}")
                time.sleep(5)
                continue
            
            # Pega top 10 cidades para ter margem
            top_cities = interest_by_region.nlargest(10, keyword)
            
            if len(top_cities) == 0:
                print(f"      ‚ö†Ô∏è  Nenhuma cidade encontrada")
                continue
            
            # Calcula percentuais
            total = top_cities[keyword].sum()
            if total == 0:
                print(f"      ‚ö†Ô∏è  Total zero - dados inv√°lidos")
                continue
            
            origins = []
            for idx, (city, row) in enumerate(top_cities.head(3).iterrows(), 1):
                percentage = (row[keyword] / total) * 100
                
                # Estrutura DUPLA para compatibilidade total
                origins.append({
                    "posicao": idx,
                    "origem": city,           # Para c√≥digo atual
                    "location": city,         # Para pulse-data.json
                    "percentual": round(percentage, 2),
                    "percent": round(percentage, 2),  # Alias
                    "impacto": "Alto" if idx == 1 else ("M√©dio" if idx == 2 else "Baixo")
                })
            
            print(f"      ‚úÖ Origens encontradas: {[o['origem'] for o in origins]}")
            return origins
            
        except Exception as e:
            print(f"      ‚ùå Erro na tentativa {attempt + 1}: {str(e)[:100]}")
            if attempt < retries - 1:
                wait_time = (attempt + 1) * 10
                print(f"      ‚è≥ Aguardando {wait_time}s antes de tentar novamente...")
                time.sleep(wait_time)
    
    # Fallback: retorna dados gen√©ricos se todas tentativas falharem
    print(f"      ‚ö†Ô∏è  FALLBACK: Usando origens gen√©ricas")
    return [
        {"posicao": 1, "origem": "S√£o Paulo/SP", "location": "S√£o Paulo/SP", 
         "percentual": 50, "percent": 50, "impacto": "Alto"},
        {"posicao": 2, "origem": "Rio de Janeiro/RJ", "location": "Rio de Janeiro/RJ",
         "percentual": 30, "percent": 30, "impacto": "M√©dio"},
        {"posicao": 3, "origem": "Belo Horizonte/MG", "location": "Belo Horizonte/MG",
         "percentual": 20, "percent": 20, "impacto": "Baixo"}
    ]


def calculate_metrics(recent_value, timeline_values):
    """Calcula m√©tricas propriet√°rias baseadas nos dados de tend√™ncia."""
    
    # Press√£o de Reserva: baseada na intensidade recente
    booking_pressure = min(0.95, max(0.50, recent_value / 100))
    
    # Buzz Social: baseado na varia√ß√£o das √∫ltimas semanas
    if len(timeline_values) >= 4:
        recent_avg = sum(timeline_values[-4:]) / 4
        previous_avg = sum(timeline_values[-8:-4]) / 4 if len(timeline_values) >= 8 else recent_avg
        volatility = abs(recent_avg - previous_avg) / (previous_avg + 1)
        social_buzz = min(0.95, max(0.40, volatility * 2 + 0.5))
    else:
        social_buzz = 0.65
    
    # Gatilho de Proximidade: baseado na tend√™ncia crescente
    if len(timeline_values) >= 3:
        last_3 = timeline_values[-3:]
        is_growing = last_3[-1] > last_3[0]
        proximity_trigger = min(0.95, max(0.50, 0.7 + (0.2 if is_growing else 0)))
    else:
        proximity_trigger = 0.70
    
    # Sentimento: baseado no valor absoluto recente
    sentiment = min(0.95, max(0.60, 0.70 + (recent_value / 200)))
    
    # Inten√ß√£o de Estadia: baseado na consist√™ncia
    if len(timeline_values) >= 4:
        std_dev = pd.Series(timeline_values[-4:]).std()
        stability = max(0, 1 - (std_dev / 50))
        stay_intent = min(0.90, max(0.50, 0.60 + (stability * 0.3)))
    else:
        stay_intent = 0.70
    
    return {
        "bookingPressure": round(booking_pressure, 4),
        "socialBuzz": round(social_buzz, 4),
        "proximityTrigger": round(proximity_trigger, 4),
        "sentiment": round(sentiment, 4),
        "stayIntent": round(stay_intent, 4)
    }


def calculate_ranking(results_list):
    """Calcula ranking de destinos por demanda (crescimento)."""
    ranked = sorted(results_list, key=lambda x: x.get('recentChange', 0), reverse=True)
    
    top_3 = []
    for idx, item in enumerate(ranked[:3], 1):
        top_3.append({
            "posicao": idx,
            "destino": item['name'],
            "demanda": round(item.get('recentChange', 0), 4)
        })
    
    return top_3


def calculate_perfil_publico(data_atual):
    """Calcula o perfil de p√∫blico baseado na sazonalidade."""
    mes = data_atual.month
    dia_semana = data_atual.weekday()
    
    if mes in [12, 1, 2]:
        return "Fam√≠lia Ver√£o"
    elif mes in [6, 7, 8]:
        return "Fam√≠lia Inverno"
    elif dia_semana >= 4:
        return "Casal Feriados"
    else:
        return "Turista Geral"


def upload_to_supabase(payload, top_3_ranking, perfil_publico):
    """Envia os dados coletados para o Supabase."""
    url = os.environ.get('SUPABASE_URL')
    key = os.environ.get('SUPABASE_KEY')
    
    if not url or not key:
        print("‚ùå ERRO: Vari√°veis SUPABASE_URL e SUPABASE_KEY n√£o encontradas!")
        return False
    
    try:
        headers = {
            "apikey": key,
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Prefer": "return=minimal"
        }
        
        # Adiciona origem_dominante e perfil_publico em cada destino
        for item in payload:
            origem = (
                item.get("topOrigins", [{}])[0].get("origem", "N/A")
                if item.get("topOrigins")
                else "N/A"
            )
            item["origem_dominante"] = origem
            item["perfil_publico"] = perfil_publico
        
        data_to_send = {
            "captured_at": datetime.now().isoformat(),
            "payload": {
                "destinations": payload,
                "top_3_ranking": top_3_ranking
            },
            "origem_dominante": payload[0].get('origem_dominante', 'N/A') if payload else 'N/A',
            "perfil_publico": perfil_publico
        }
        
        endpoint = f"{url}/rest/v1/demand_pulse_snapshots"
        response = requests.post(endpoint, headers=headers, json=data_to_send, timeout=15)
        
        if response.status_code in [200, 201]:
            print("\n" + "="*60)
            print("‚úÖ SUCESSO: Dados enviados ao Supabase!")
            print(f"üìä Destinos processados: {len(payload)}")
            print(f"üèÜ Top 3 Ranking: {[r['destino'] for r in top_3_ranking]}")
            print("="*60)
            return True
        else:
            print(f"\n‚ùå Erro no upload para Supabase: {response.status_code}")
            print(f"Resposta: {response.text[:200]}")
            return False
            
    except Exception as e:
        print(f"\n‚ùå ERRO CR√çTICO no upload: {e}")
        return False

def get_trends_data_v3(destinos_dict):
    """
    Coleta dados do Google Trends para 10 destinos.
    VERS√ÉO 3.0: Com busca REAL de origens geogr√°ficas e retry logic melhorado.
    """
    pytrends = TrendReq(
        hl='pt-BR',
        tz=180,
        retries=5,
        backoff_factor=0.5,
        timeout=(15, 30)
    )
    
    results_map = {}
    total_destinos = len(destinos_dict)
    destinos_processados = 0
    destinos_com_erro = 0
    
    print(f"\nüìç Total de destinos para processar: {total_destinos}")
    print("="*60)
    
    for idx, (nome, info) in enumerate(destinos_dict.items(), 1):
        print(f"\n[{idx}/{total_destinos}] üéØ Processando: {nome}")
        print(f"   Keyword: {info['keyword']}")
        
        success = False
        for attempt in range(3):  # 3 tentativas por destino
            try:
                if attempt > 0:
                    wait_time = attempt * 15
                    print(f"   ‚è≥ Tentativa {attempt + 1}/3 - Aguardando {wait_time}s...")
                    time.sleep(wait_time)
                
                # Coleta timeline de interesse
                print(f"   üìä Coletando dados de tend√™ncia...")
                pytrends.build_payload([info['keyword']], geo='BR', timeframe='today 3-m')
                df = pytrends.interest_over_time()
                
                if df.empty or info['keyword'] not in df.columns:
                    print(f"   ‚ö†Ô∏è  Sem dados de tend√™ncia")
                    continue
                
                # Calcula m√©tricas de tend√™ncia
                recent = df[info['keyword']].iloc[-7:].mean()
                previous = df[info['keyword']].iloc[-28:-7].mean()
                change = (recent - previous) / previous if previous > 0 else 0
                timeline = [round(max(0.1, x), 1) for x in df[info['keyword']].resample('W').mean().tail(8).tolist()]
                
                print(f"   ‚úÖ Timeline coletada: {len(timeline)} semanas")
                print(f"   üìà Varia√ß√£o recente: {change*100:.1f}%")
                
                # Coleta ORIGENS GEOGR√ÅFICAS (CR√çTICO!)
                time.sleep(random.uniform(5, 10))  # Rate limiting
                geographic_origins = get_geographic_origins(pytrends, info['keyword'])
                
                # Coleta previs√£o do tempo
                print(f"   üå§Ô∏è  Coletando previs√£o do tempo...")
                weather = get_weather(info['lat'], info['lon'])
                
                # Calcula m√©tricas propriet√°rias
                metrics = calculate_metrics(recent, timeline)
                
                # Monta resultado completo
                results_map[info['id']] = {
                    "id": info['id'],
                    "name": nome,
                    "recentChange": round(change, 4),
                    "timeline": timeline,
                    "topOrigins": geographic_origins,  # ‚úÖ ORIGENS REAIS!
                    "weather": weather,
                    "insight": info['insight_base'].format(
                        status="em alta" if change > 0.05 else ("em queda" if change < -0.05 else "est√°vel")
                    ),
                    **metrics
                }
                
                destinos_processados += 1
                success = True
                print(f"   ‚úÖ {nome} processado com sucesso!")
                
                # Rate limiting entre destinos
                if idx < total_destinos:
                    wait = random.uniform(20, 30)
                    print(f"   ‚è≥ Aguardando {wait:.0f}s antes do pr√≥ximo destino...")
                    time.sleep(wait)
                
                break  # Sucesso - sai do loop de tentativas
                
            except Exception as e:
                error_msg = str(e)[:150]
                print(f"   ‚ùå Erro na tentativa {attempt + 1}: {error_msg}")
                
                if attempt == 2:  # √öltima tentativa falhou
                    destinos_com_erro += 1
                    print(f"   ‚ö†Ô∏è  FALHA: {nome} n√£o p√¥de ser processado ap√≥s 3 tentativas")
                    time.sleep(10)
        
        if not success:
            print(f"   ‚ö†Ô∏è  Pulando {nome} - continuando com pr√≥ximo destino...")
    
    print("\n" + "="*60)
    print(f"üìä RESUMO DA COLETA:")
    print(f"   ‚úÖ Processados: {destinos_processados}/{total_destinos}")
    print(f"   ‚ùå Com erro: {destinos_com_erro}/{total_destinos}")
    print(f"   üìà Taxa de sucesso: {(destinos_processados/total_destinos)*100:.1f}%")
    print("="*60)
    
    return list(results_map.values())


# =================================================================
# CONFIGURA√á√ÉO DOS DESTINOS
# =================================================================

destinos_config = {
    "Monte Verde": {
        "id": "monte_verde_mg",
        "keyword": "Monte Verde MG",
        "lat": -22.8627,
        "lon": -46.0377,
        "insight_base": "Demanda por Monte Verde segue {status}."
    },
    "Campos do Jord√£o": {
        "id": "campos_do_jordao_sp",
        "keyword": "Campos do Jord√£o",
        "lat": -22.7394,
        "lon": -45.5914,
        "insight_base": "Campos do Jord√£o apresenta comportamento {status}."
    },
    "Gramado + Canela": {
        "id": "gramado_canela_rs",
        "keyword": "Gramado RS",
        "lat": -29.3746,
        "lon": -50.8764,
        "insight_base": "Serra Ga√∫cha {status}."
    },
    "S√£o Louren√ßo": {
        "id": "sao_lourenco_mg",
        "keyword": "S√£o Louren√ßo MG",
        "lat": -22.1158,
        "lon": -45.0547,
        "insight_base": "S√£o Louren√ßo {status}."
    },
    "Po√ßos de Caldas": {
        "id": "pocos_de_caldas_mg",
        "keyword": "Po√ßos de Caldas",
        "lat": -21.7867,
        "lon": -46.5619,
        "insight_base": "Po√ßos {status}."
    },
    "S√£o Bento do Sapuca√≠": {
        "id": "sao_bento_sapucai_sp",
        "keyword": "S√£o Bento do Sapuca√≠",
        "lat": -22.6886,
        "lon": -45.7325,
        "insight_base": "S√£o Bento {status}."
    },
    "Passa Quatro": {
        "id": "passa_quatro_mg",
        "keyword": "Passa Quatro MG",
        "lat": -22.3883,
        "lon": -44.9681,
        "insight_base": "Passa Quatro {status}."
    },
    "Serra Negra": {
        "id": "serra_negra_sp",
        "keyword": "Serra Negra SP",
        "lat": -22.6122,
        "lon": -46.7002,
        "insight_base": "Serra Negra {status}."
    },
    "Gon√ßalves": {
        "id": "goncalves_mg",
        "keyword": "Gon√ßalves MG",
        "lat": -22.6561,
        "lon": -45.8508,
        "insight_base": "Gon√ßalves {status}."
    },
    "Santo Ant√¥nio do Pinhal": {
        "id": "santo_antonio_pinhal_sp",
        "keyword": "Santo Ant√¥nio do Pinhal",
        "lat": -22.8247,
        "lon": -45.6671,
        "insight_base": "Santo Ant√¥nio {status}."
    }
}


# =================================================================
# EXECU√á√ÉO PRINCIPAL
# =================================================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("üöÄ DEMAND PULSE V3.0 - MOTOR CORRIGIDO")
    print("üìÖ Data/Hora:", datetime.now().strftime("%d/%m/%Y %H:%M:%S"))
    print("="*60)
    
    # Coleta dados
    final_data = get_trends_data_v3(destinos_config)
    
    if not final_data or len(final_data) == 0:
        print("\n‚ùå ERRO CR√çTICO: Nenhum dado foi coletado!")
        print("Verifique sua conex√£o e tente novamente.")
        import sys
        sys.exit(1)
    
    # Calcula perfil de p√∫blico e ranking
    perfil_publico = calculate_perfil_publico(datetime.now())
    top_3_ranking = calculate_ranking(final_data)
    
    print(f"\nüìä Perfil de P√∫blico: {perfil_publico}")
    print(f"üèÜ Top 3 Destinos por Crescimento:")
    for rank in top_3_ranking:
        print(f"   {rank['posicao']}¬∫ - {rank['destino']}: {rank['demanda']*100:.1f}%")
    
    # Salva localmente (backup)
    try:
        backup_file = 'pulse-data-backup.json'
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump({d['id']: d for d in final_data}, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ Backup salvo em: {backup_file}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Erro ao salvar backup: {e}")
    
    # Upload para Supabase
    print("\nüì§ Enviando dados para Supabase...")
    success = upload_to_supabase(final_data, top_3_ranking, perfil_publico)
    
    if success:
        print("\n" + "="*60)
        print("üéâ PROCESSO CONCLU√çDO COM SUCESSO!")
        print(f"‚úÖ {len(final_data)} destinos atualizados no Supabase")
        print("="*60 + "\n")
        import sys
        sys.exit(0)
    else:
        print("\n" + "="*60)
        print("‚ö†Ô∏è  PROCESSO CONCLU√çDO COM AVISOS")
        print("Dados coletados mas houve erro no upload para Supabase")
        print("="*60 + "\n")
        import sys
        sys.exit(1)
